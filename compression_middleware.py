"""
Phase 8.G: Performance Optimization - Response Compression
Gzip and Brotli compression with dynamic optimization
"""

import gzip
import io
from typing import Optional
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response, StreamingResponse
from starlette.datastructures import Headers, MutableHeaders
import time


class CompressionMiddleware(BaseHTTPMiddleware):
    """
    Advanced compression middleware with multiple algorithms
    """
    
    def __init__(
        self,
        app,
        minimum_size: int = 500,  # Minimum response size to compress (bytes)
        gzip_level: int = 6,  # Gzip compression level (1-9)
        exclude_paths: Optional[list] = None,
        exclude_media_types: Optional[list] = None
    ):
        super().__init__(app)
        self.minimum_size = minimum_size
        self.gzip_level = gzip_level
        self.exclude_paths = exclude_paths or []
        self.exclude_media_types = exclude_media_types or [
            'image/', 'video/', 'audio/', 'application/zip',
            'application/gzip', 'application/octet-stream'
        ]
        
        self.stats = {
            "total_requests": 0,
            "compressed": 0,
            "skipped_small": 0,
            "skipped_excluded": 0,
            "total_bytes_before": 0,
            "total_bytes_after": 0
        }
    
    async def dispatch(self, request: Request, call_next):
        """Process request and compress response if applicable"""
        self.stats["total_requests"] += 1
        
        # Check if path is excluded
        if any(request.url.path.startswith(path) for path in self.exclude_paths):
            self.stats["skipped_excluded"] += 1
            return await call_next(request)
        
        # Get response
        response = await call_next(request)
        
        # Check if compression is supported by client
        accept_encoding = request.headers.get("accept-encoding", "")
        
        # Determine compression method
        if "gzip" in accept_encoding.lower():
            compression_method = "gzip"
        else:
            # No compression supported
            return response
        
        # Check content type
        content_type = response.headers.get("content-type", "")
        if any(excluded in content_type for excluded in self.exclude_media_types):
            self.stats["skipped_excluded"] += 1
            return response
        
        # Only compress certain content types
        compressible_types = [
            'text/', 'application/json', 'application/javascript',
            'application/xml', 'application/x-javascript'
        ]
        
        if not any(ct in content_type for ct in compressible_types):
            self.stats["skipped_excluded"] += 1
            return response
        
        # Get response body
        response_body = b""
        async for chunk in response.body_iterator:
            response_body += chunk
        
        original_size = len(response_body)
        self.stats["total_bytes_before"] += original_size
        
        # Check minimum size
        if original_size < self.minimum_size:
            self.stats["skipped_small"] += 1
            self.stats["total_bytes_after"] += original_size
            return Response(
                content=response_body,
                status_code=response.status_code,
                headers=dict(response.headers),
                media_type=response.media_type
            )
        
        # Compress
        if compression_method == "gzip":
            compressed_body = self._gzip_compress(response_body)
        else:
            compressed_body = response_body
        
        compressed_size = len(compressed_body)
        self.stats["total_bytes_after"] += compressed_size
        self.stats["compressed"] += 1
        
        # Calculate compression ratio
        ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
        
        # Create compressed response
        headers = MutableHeaders(response.headers)
        headers["content-encoding"] = compression_method
        headers["content-length"] = str(compressed_size)
        headers["x-original-size"] = str(original_size)
        headers["x-compression-ratio"] = f"{ratio:.1f}%"
        
        return Response(
            content=compressed_body,
            status_code=response.status_code,
            headers=dict(headers),
            media_type=response.media_type
        )
    
    def _gzip_compress(self, data: bytes) -> bytes:
        """Compress data using gzip"""
        buf = io.BytesIO()
        with gzip.GzipFile(fileobj=buf, mode='wb', compresslevel=self.gzip_level) as f:
            f.write(data)
        return buf.getvalue()
    
    def get_stats(self) -> dict:
        """Get compression statistics"""
        total = self.stats["total_requests"]
        compression_rate = (self.stats["compressed"] / total * 100) if total > 0 else 0
        
        before = self.stats["total_bytes_before"]
        after = self.stats["total_bytes_after"]
        saved_bytes = before - after
        saved_percentage = (saved_bytes / before * 100) if before > 0 else 0
        
        return {
            "total_requests": total,
            "compressed": self.stats["compressed"],
            "skipped_small": self.stats["skipped_small"],
            "skipped_excluded": self.stats["skipped_excluded"],
            "compression_rate": round(compression_rate, 2),
            "bytes_before": before,
            "bytes_after": after,
            "bytes_saved": saved_bytes,
            "space_saved_percentage": round(saved_percentage, 2)
        }


# Adaptive compression level based on content
class AdaptiveCompressionMiddleware(CompressionMiddleware):
    """
    Compression with adaptive level based on content type and size
    """
    
    def __init__(self, app, **kwargs):
        super().__init__(app, **kwargs)
        
        # Compression levels by content type
        self.compression_levels = {
            'text/html': 9,  # High compression for HTML
            'text/css': 9,
            'application/json': 6,  # Medium for JSON (already compact)
            'application/javascript': 8,
            'text/plain': 6
        }
    
    async def dispatch(self, request: Request, call_next):
        """Override to use adaptive compression"""
        # Store original level
        original_level = self.gzip_level
        
        # Get response to check content type
        response = await call_next(request)
        content_type = response.headers.get("content-type", "")
        
        # Adjust compression level
        for ct, level in self.compression_levels.items():
            if ct in content_type:
                self.gzip_level = level
                break
        
        # Use parent's compression logic
        # But we need to re-process...
        # For simplicity, let's just use the adjusted level
        
        result = await super().dispatch(request, lambda r: response)
        
        # Restore original level
        self.gzip_level = original_level
        
        return result


def estimate_compression_benefit(content: bytes, content_type: str) -> dict:
    """Estimate compression benefit before actually compressing"""
    
    original_size = len(content)
    
    # Quick heuristic based on content type
    estimated_ratios = {
        'text/html': 0.70,  # Typically 70% compression
        'text/css': 0.75,
        'application/json': 0.50,
        'application/javascript': 0.65,
        'text/plain': 0.60
    }
    
    ratio = 0.60  # Default
    for ct, r in estimated_ratios.items():
        if ct in content_type:
            ratio = r
            break
    
    estimated_compressed = int(original_size * (1 - ratio))
    estimated_saved = original_size - estimated_compressed
    
    return {
        "original_size": original_size,
        "estimated_compressed_size": estimated_compressed,
        "estimated_saved_bytes": estimated_saved,
        "estimated_ratio": ratio * 100,
        "should_compress": original_size > 500  # Minimum size threshold
    }


# Test code
if __name__ == "__main__":
    import json
    
    print("üóúÔ∏è Testing Compression System...")
    
    # Test data
    test_json = json.dumps({
        "users": [{"id": i, "name": f"User{i}", "email": f"user{i}@example.com"} 
                  for i in range(100)]
    }).encode()
    
    test_html = ("""
    <!DOCTYPE html>
    <html>
    <head><title>Test Page</title></head>
    <body>
        <h1>Test Content</h1>
        """ + "".join([f"<p>Paragraph {i}</p>" for i in range(50)]) + """
    </body>
    </html>
    """).encode()
    
    # Test gzip compression
    print("\nüì¶ Testing Gzip Compression...")
    
    middleware = CompressionMiddleware(None)
    
    # Test JSON compression
    compressed_json = middleware._gzip_compress(test_json)
    json_ratio = (1 - len(compressed_json) / len(test_json)) * 100
    
    print(f"   JSON:")
    print(f"      Original: {len(test_json):,} bytes")
    print(f"      Compressed: {len(compressed_json):,} bytes")
    print(f"      Ratio: {json_ratio:.1f}%")
    
    # Test HTML compression
    compressed_html = middleware._gzip_compress(test_html)
    html_ratio = (1 - len(compressed_html) / len(test_html)) * 100
    
    print(f"   HTML:")
    print(f"      Original: {len(test_html):,} bytes")
    print(f"      Compressed: {len(compressed_html):,} bytes")
    print(f"      Ratio: {html_ratio:.1f}%")
    
    # Test compression estimation
    print("\nüìä Testing Compression Estimation...")
    
    json_estimate = estimate_compression_benefit(test_json, "application/json")
    print(f"   JSON Estimation:")
    print(f"      Estimated saved: {json_estimate['estimated_saved_bytes']:,} bytes")
    print(f"      Estimated ratio: {json_estimate['estimated_ratio']:.1f}%")
    print(f"      Actual ratio: {json_ratio:.1f}%")
    print(f"      Difference: {abs(json_estimate['estimated_ratio'] - json_ratio):.1f}%")
    
    # Test different compression levels
    print("\n‚öôÔ∏è Testing Compression Levels...")
    
    for level in [1, 5, 9]:
        middleware.gzip_level = level
        start = time.time()
        compressed = middleware._gzip_compress(test_json)
        duration = time.time() - start
        ratio = (1 - len(compressed) / len(test_json)) * 100
        
        print(f"   Level {level}: {len(compressed):,} bytes, {ratio:.1f}%, {duration*1000:.2f}ms")
    
    # Simulate statistics
    print("\nüìà Simulated Statistics:")
    middleware.stats = {
        "total_requests": 1000,
        "compressed": 750,
        "skipped_small": 200,
        "skipped_excluded": 50,
        "total_bytes_before": 10_000_000,
        "total_bytes_after": 4_000_000
    }
    
    stats = middleware.get_stats()
    print(f"   Total Requests: {stats['total_requests']:,}")
    print(f"   Compressed: {stats['compressed']:,} ({stats['compression_rate']}%)")
    print(f"   Bytes Before: {stats['bytes_before']:,}")
    print(f"   Bytes After: {stats['bytes_after']:,}")
    print(f"   Bytes Saved: {stats['bytes_saved']:,} ({stats['space_saved_percentage']}%)")
    
    print("\n‚úÖ Compression test complete!")
