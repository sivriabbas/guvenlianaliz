"""
MODEL TRAINER - ML Modellerini GerÃ§ek Veri ile EÄŸitir
Phase 6: Toplanan gerÃ§ek maÃ§ verisi ile XGBoost ve LightGBM modellerini eÄŸitir
"""
import pandas as pd
import numpy as np
from pathlib import Path
from ml_model_manager import MLModelManager
from typing import Dict, List
import json
from datetime import datetime

class ModelTrainer:
    """GerÃ§ek veri ile model eÄŸitimi"""
    
    def __init__(self, data_path: str):
        self.data_path = Path(data_path)
        self.ml_manager = MLModelManager()
        self.results = {}
        
    def load_training_data(self) -> tuple:
        """CSV'den eÄŸitim verisini yÃ¼kle"""
        print(f"\n{'='*70}")
        print(f"ğŸ“Š EÄÄ°TÄ°M VERÄ°SÄ° YÃœKLENÄ°YOR")
        print(f"{'='*70}")
        
        if not self.data_path.exists():
            raise FileNotFoundError(f"Veri dosyasÄ± bulunamadÄ±: {self.data_path}")
        
        # CSV oku
        df = pd.read_csv(self.data_path)
        print(f"âœ… {len(df)} maÃ§ verisi yÃ¼klendi")
        
        # Feature columns (17 faktÃ¶r)
        feature_cols = [
            'form', 'elo_diff', 'home_advantage', 'h2h', 'league_position',
            'injuries', 'motivation', 'recent_xg',
            'weather', 'referee', 'betting_odds',
            'tactical_matchup', 'transfer_impact', 'squad_experience',
            'match_importance', 'fatigue', 'recent_performance'
        ]
        
        # Features ve labels ayÄ±r
        X = df[feature_cols].values
        y = df['result'].values
        
        print(f"\nğŸ“ˆ Veri Ä°statistikleri:")
        print(f"  Features shape: {X.shape}")
        print(f"  Labels shape: {y.shape}")
        
        # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
        unique, counts = np.unique(y, return_counts=True)
        class_dist = dict(zip(unique, counts))
        print(f"\nğŸ¯ SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:")
        labels = {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}
        for cls, count in class_dist.items():
            pct = count / len(y) * 100
            print(f"  {labels[cls]}: {count} (%{pct:.1f})")
        
        return X, y, df
    
    def train_all_models(self, X: np.ndarray, y: np.ndarray):
        """TÃ¼m modelleri eÄŸit ve deÄŸerlendir"""
        print(f"\n{'='*70}")
        print(f"ğŸ“ MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR")
        print(f"{'='*70}")
        
        models_to_train = [
            ('xgboost', 'xgb_real_v1'),
            ('lightgbm', 'lgb_real_v1')
        ]
        
        for model_type, model_name in models_to_train:
            print(f"\n{'â”€'*70}")
            print(f"ğŸ¤– {model_type.upper()} EÄŸitiliyor...")
            print(f"{'â”€'*70}")
            
            try:
                result = self.ml_manager.train_model(
                    X, y,
                    model_type=model_type,
                    model_name=model_name,
                    test_size=0.2
                )
                
                # SonuÃ§larÄ± kaydet
                self.results[model_name] = {
                    'type': model_type,
                    'accuracy': result['accuracy'],
                    'log_loss': result['log_loss'],
                    'trained_at': datetime.now().isoformat()
                }
                
                # Metrikleri gÃ¶ster
                print(f"\nâœ… EÄŸitim TamamlandÄ±!")
                print(f"  ğŸ“Š Accuracy: {result['accuracy']:.4f} (%{result['accuracy']*100:.2f})")
                print(f"  ğŸ“‰ Log Loss: {result['log_loss']:.4f}")
                
                # Modeli kaydet
                self.ml_manager.save_model(model_name)
                
                # Confusion matrix
                self._print_confusion_matrix(result['y_test'], result['y_pred'])
                
                # Feature importance
                self._print_feature_importance(model_name)
                
            except Exception as e:
                print(f"âŒ {model_type} eÄŸitim hatasÄ±: {e}")
                continue
    
    def _print_confusion_matrix(self, y_test: np.ndarray, y_pred: np.ndarray):
        """Confusion matrix gÃ¶ster"""
        from sklearn.metrics import confusion_matrix
        
        cm = confusion_matrix(y_test, y_pred)
        
        print(f"\nğŸ“Š Confusion Matrix:")
        print(f"               Predicted")
        print(f"            Home  Draw  Away")
        print(f"  Actual")
        print(f"  Home     {cm[0][0]:4d}  {cm[0][1]:4d}  {cm[0][2]:4d}")
        print(f"  Draw     {cm[1][0]:4d}  {cm[1][1]:4d}  {cm[1][2]:4d}")
        print(f"  Away     {cm[2][0]:4d}  {cm[2][1]:4d}  {cm[2][2]:4d}")
    
    def _print_feature_importance(self, model_name: str, top_n: int = 10):
        """Feature importance gÃ¶ster"""
        print(f"\nğŸ“ˆ Top {top_n} Ã–nemli FaktÃ¶rler:")
        
        importance = self.ml_manager.get_feature_importance(model_name)
        
        for i, (feature, score) in enumerate(importance[:top_n], 1):
            bar = "â–ˆ" * int(score * 50)
            print(f"  {i:2d}. {feature:20s} {score:6.4f} {bar}")
    
    def save_training_report(self, output_path: str = "models/training_report.json"):
        """EÄŸitim raporunu kaydet"""
        report = {
            'training_date': datetime.now().isoformat(),
            'data_path': str(self.data_path),
            'models': self.results
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… EÄŸitim raporu kaydedildi: {output_path}")
    
    def compare_models(self):
        """Modelleri karÅŸÄ±laÅŸtÄ±r"""
        if len(self.results) < 2:
            return
        
        print(f"\n{'='*70}")
        print(f"âš”ï¸ MODEL KARÅILAÅTIRMA")
        print(f"{'='*70}")
        
        print(f"\n{'Model':<20} {'Accuracy':<12} {'Log Loss':<12}")
        print(f"{'-'*44}")
        
        sorted_models = sorted(
            self.results.items(),
            key=lambda x: x[1]['accuracy'],
            reverse=True
        )
        
        for model_name, metrics in sorted_models:
            acc = metrics['accuracy']
            loss = metrics['log_loss']
            print(f"{model_name:<20} {acc:>10.4f}  {loss:>10.4f}")
        
        # En iyi model
        best_model = sorted_models[0]
        print(f"\nğŸ† EN Ä°YÄ° MODEL: {best_model[0]}")
        print(f"   Accuracy: %{best_model[1]['accuracy']*100:.2f}")
        print(f"   Log Loss: {best_model[1]['log_loss']:.4f}")


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ¯ MODEL EÄÄ°TÄ°M SÄ°STEMÄ° - PHASE 6")
    print("="*70)
    
    # Veri dosyasÄ±nÄ± bul
    data_dir = Path("ml_training_data")
    csv_files = list(data_dir.glob("*.csv"))
    
    if not csv_files:
        print("\nâŒ EÄŸitim verisi bulunamadÄ±!")
        print("Ã–nce 'python data_collector.py' ile veri toplayÄ±n")
        exit(1)
    
    print(f"\nğŸ“ Bulunan veri dosyalarÄ±:")
    for i, csv_file in enumerate(csv_files, 1):
        print(f"  {i}. {csv_file.name}")
    
    # Ä°lk dosyayÄ± kullan (veya kullanÄ±cÄ±dan seÃ§)
    data_file = csv_files[0]
    print(f"\nâœ… KullanÄ±lacak dosya: {data_file.name}")
    
    response = input("\nâ“ Model eÄŸitimine baÅŸlamak istiyor musunuz? (e/h): ")
    
    if response.lower() == 'e':
        # Trainer oluÅŸtur
        trainer = ModelTrainer(data_file)
        
        # Veriyi yÃ¼kle
        X, y, df = trainer.load_training_data()
        
        # Modelleri eÄŸit
        trainer.train_all_models(X, y)
        
        # Modelleri karÅŸÄ±laÅŸtÄ±r
        trainer.compare_models()
        
        # Rapor kaydet
        trainer.save_training_report()
        
        print(f"\n{'='*70}")
        print(f"ğŸ‰ EÄÄ°TÄ°M TAMAMLANDI!")
        print(f"{'='*70}")
        print(f"âœ… Modeller 'models/' dizinine kaydedildi")
        print(f"ğŸ¯ API'yi yeniden baÅŸlatarak yeni modelleri kullanabilirsiniz")
        print(f"\nğŸ’¡ Komut: python simple_fastapi.py")
    else:
        print("\nâ¸ï¸ Ä°ÅŸlem iptal edildi")
