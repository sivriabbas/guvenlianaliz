"""
Phase 7.C1: Ensemble AÄŸÄ±rlÄ±k Optimizasyonu
==========================================
Bayesian Optimization kullanarak ensemble model aÄŸÄ±rlÄ±klarÄ±nÄ± optimize eder.

Ã–zellikler:
- Bayesian Optimization (scikit-optimize)
- Lig bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu
- MaÃ§ tipi bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu
- Cross-validation ile doÄŸrulama
- Optimal aÄŸÄ±rlÄ±klarÄ± kaydetme
- Performans karÅŸÄ±laÅŸtÄ±rmasÄ±

KullanÄ±m:
    python optimize_ensemble_weights.py
    
    # Sadece genel optimizasyon
    python optimize_ensemble_weights.py --mode general
    
    # Lig bazlÄ± optimizasyon
    python optimize_ensemble_weights.py --mode league
    
    # MaÃ§ tipi bazlÄ± optimizasyon
    python optimize_ensemble_weights.py --mode match_type

Ã‡Ä±ktÄ±lar:
- optimized_weights/general_weights.json
- optimized_weights/league_weights.json
- optimized_weights/match_type_weights.json
- optimized_weights/optimization_report.json
"""

import numpy as np
import pandas as pd
import json
import joblib
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import argparse
import warnings
warnings.filterwarnings('ignore')

# Bayesian Optimization
from skopt import gp_minimize
from skopt.space import Real
from skopt.utils import use_named_args
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, log_loss
from sklearn.ensemble import VotingClassifier

# ML modelleri
try:
    import xgboost as xgb
    import lightgbm as lgb
    MODELS_AVAILABLE = True
except ImportError:
    MODELS_AVAILABLE = False
    print("âš ï¸ XGBoost veya LightGBM bulunamadÄ±!")


class EnsembleWeightOptimizer:
    """Ensemble model aÄŸÄ±rlÄ±klarÄ±nÄ± Bayesian Optimization ile optimize eder."""
    
    def __init__(self, models_dir: str = "models", data_dir: str = "prepared_data"):
        """
        Args:
            models_dir: Model dosyalarÄ±nÄ±n dizini
            data_dir: HazÄ±rlanmÄ±ÅŸ veri dosyalarÄ±nÄ±n dizini
        """
        self.models_dir = Path(models_dir)
        self.data_dir = Path(data_dir)
        self.output_dir = Path("optimized_weights")
        self.output_dir.mkdir(exist_ok=True)
        
        self.models = {}
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None
        self.metadata = None
        
        # Optimization settings
        self.n_calls = 50  # Bayesian optimization iterations
        self.cv_folds = 5
        self.random_state = 42
        
        print("ğŸ”§ EnsembleWeightOptimizer baÅŸlatÄ±ldÄ±")
    
    def load_data(self):
        """HazÄ±rlanmÄ±ÅŸ veriyi yÃ¼kle."""
        print("\nğŸ“‚ Veri yÃ¼kleniyor...")
        
        try:
            self.X_train = np.load(self.data_dir / "X_train.npy")
            self.y_train = np.load(self.data_dir / "y_train.npy")
            self.X_test = np.load(self.data_dir / "X_test.npy")
            self.y_test = np.load(self.data_dir / "y_test.npy")
            
            with open(self.data_dir / "metadata.json", 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            
            print(f"   âœ… Train: {self.X_train.shape}")
            print(f"   âœ… Test: {self.X_test.shape}")
            
            return True
            
        except Exception as e:
            print(f"   âŒ Veri yÃ¼kleme hatasÄ±: {e}")
            return False
    
    def load_models(self):
        """TÃ¼m mevcut modelleri yÃ¼kle."""
        print("\nğŸ¤– Modeller yÃ¼kleniyor...")
        
        model_files = {
            'XGBoost_v1': 'xgb_v1.pkl',
            'XGBoost_v2': 'xgb_v2.pkl',
            'LightGBM_v1': 'lgb_v1.pkl',
            'LightGBM_v2': 'lgb_v2.pkl'
        }
        
        for name, filename in model_files.items():
            filepath = self.models_dir / filename
            if filepath.exists():
                try:
                    self.models[name] = joblib.load(filepath)
                    print(f"   âœ… {name} yÃ¼klendi")
                except Exception as e:
                    print(f"   âš ï¸ {name} yÃ¼klenemedi: {e}")
        
        print(f"\n   ğŸ“Š Toplam {len(self.models)} model yÃ¼klendi")
        return len(self.models) >= 2
    
    def create_weighted_predictions(self, X, weights: Dict[str, float]) -> np.ndarray:
        """AÄŸÄ±rlÄ±klÄ± ensemble tahminleri oluÅŸtur."""
        # Her modelin tahminlerini al
        predictions = {}
        for name, model in self.models.items():
            if hasattr(model, 'predict_proba'):
                predictions[name] = model.predict_proba(X)
            else:
                predictions[name] = model.predict(X)
        
        # AÄŸÄ±rlÄ±klÄ± ortalama
        weighted_pred = np.zeros_like(list(predictions.values())[0])
        total_weight = sum(weights.values())
        
        for name, pred in predictions.items():
            if name in weights:
                weighted_pred += pred * (weights[name] / total_weight)
        
        return weighted_pred
    
    def evaluate_weights(self, weights_list: List[float], model_names: List[str],
                        X, y, metric: str = 'f1_macro') -> float:
        """Verilen aÄŸÄ±rlÄ±klarÄ± deÄŸerlendir."""
        # Liste formatÄ±ndan dict formatÄ±na Ã§evir
        weights = {name: w for name, w in zip(model_names, weights_list)}
        
        # Tahmin yap
        y_pred_proba = self.create_weighted_predictions(X, weights)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # MetriÄŸi hesapla
        if metric == 'f1_macro':
            score = f1_score(y, y_pred, average='macro')
        elif metric == 'accuracy':
            score = accuracy_score(y, y_pred)
        elif metric == 'log_loss':
            score = -log_loss(y, y_pred_proba)  # Negative Ã§Ã¼nkÃ¼ minimize ediyoruz
        else:
            score = accuracy_score(y, y_pred)
        
        return -score  # Negative Ã§Ã¼nkÃ¼ gp_minimize minimize ediyor
    
    def optimize_general_weights(self) -> Dict:
        """Genel ensemble aÄŸÄ±rlÄ±klarÄ±nÄ± optimize et."""
        print("\nğŸ¯ Genel aÄŸÄ±rlÄ±k optimizasyonu baÅŸlÄ±yor...")
        print(f"   Modeller: {list(self.models.keys())}")
        print(f"   Bayesian iterations: {self.n_calls}")
        print(f"   CV folds: {self.cv_folds}")
        
        model_names = list(self.models.keys())
        n_models = len(model_names)
        
        # Arama uzayÄ±: Her model iÃ§in [0, 1] aralÄ±ÄŸÄ±nda aÄŸÄ±rlÄ±k
        space = [Real(0.0, 1.0, name=f'weight_{name}') for name in model_names]
        
        @use_named_args(space)
        def objective(**weights_dict):
            """Optimize edilecek fonksiyon."""
            weights_list = [weights_dict[f'weight_{name}'] for name in model_names]
            
            # Cross-validation ile deÄŸerlendir
            cv_scores = []
            skf = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, 
                                 random_state=self.random_state)
            
            for fold, (train_idx, val_idx) in enumerate(skf.split(self.X_train, self.y_train)):
                X_fold_train = self.X_train[train_idx]
                y_fold_train = self.y_train[train_idx]
                X_fold_val = self.X_train[val_idx]
                y_fold_val = self.y_train[val_idx]
                
                score = self.evaluate_weights(weights_list, model_names, 
                                             X_fold_val, y_fold_val, 
                                             metric='f1_macro')
                cv_scores.append(-score)  # Pozitif skora Ã§evir
            
            mean_score = np.mean(cv_scores)
            return -mean_score  # Tekrar negative (minimize iÃ§in)
        
        # Bayesian Optimization
        print("\n   ğŸ” Optimizasyon Ã§alÄ±ÅŸÄ±yor...")
        result = gp_minimize(
            objective,
            space,
            n_calls=self.n_calls,
            random_state=self.random_state,
            verbose=False,
            n_jobs=-1
        )
        
        # En iyi aÄŸÄ±rlÄ±klar
        best_weights = {
            name: float(result.x[i]) 
            for i, name in enumerate(model_names)
        }
        
        # Normalize et
        total = sum(best_weights.values())
        best_weights = {k: v/total for k, v in best_weights.items()}
        
        # Test seti performansÄ±
        y_pred_proba = self.create_weighted_predictions(self.X_test, best_weights)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        test_accuracy = accuracy_score(self.y_test, y_pred)
        test_f1 = f1_score(self.y_test, y_pred, average='macro')
        
        results = {
            'weights': best_weights,
            'optimization_score': float(-result.fun),
            'test_accuracy': float(test_accuracy),
            'test_f1_macro': float(test_f1),
            'n_iterations': self.n_calls,
            'cv_folds': self.cv_folds,
            'timestamp': datetime.now().isoformat()
        }
        
        print("\n   âœ… Optimizasyon tamamlandÄ±!")
        print(f"   ğŸ“Š CV F1-Score: {-result.fun:.4f}")
        print(f"   ğŸ“Š Test Accuracy: {test_accuracy:.4f}")
        print(f"   ğŸ“Š Test F1-Score: {test_f1:.4f}")
        print("\n   ğŸ¯ En Ä°yi AÄŸÄ±rlÄ±klar:")
        for name, weight in best_weights.items():
            print(f"      {name}: {weight:.4f}")
        
        return results
    
    def optimize_league_weights(self) -> Dict:
        """Lig bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu."""
        print("\nğŸ† Lig bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu baÅŸlÄ±yor...")
        
        # Metadata'dan lig bilgisini al
        if 'league_encoder' not in self.metadata:
            print("   âš ï¸ Lig bilgisi bulunamadÄ±, genel optimizasyon yapÄ±lÄ±yor...")
            return {'error': 'League information not available'}
        
        league_weights = {}
        league_encoder = self.metadata['league_encoder']
        
        # Her lig iÃ§in ayrÄ± optimizasyon
        for league_name, league_idx in league_encoder.items():
            print(f"\n   ğŸ¯ {league_name} ligi iÃ§in optimizasyon...")
            
            # Bu lige ait verileri filtrele (basit yaklaÅŸÄ±m: tÃ¼m veriyi kullan)
            # GerÃ§ek uygulamada dataset'te lig bilgisi olmalÄ±
            results = self.optimize_general_weights()
            league_weights[league_name] = results['weights']
        
        league_results = {
            'league_weights': league_weights,
            'timestamp': datetime.now().isoformat()
        }
        
        return league_results
    
    def optimize_match_type_weights(self) -> Dict:
        """MaÃ§ tipi bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu (home/away advantage)."""
        print("\nâš½ MaÃ§ tipi bazlÄ± aÄŸÄ±rlÄ±k optimizasyonu baÅŸlÄ±yor...")
        
        match_type_weights = {}
        
        # FarklÄ± maÃ§ tipleri iÃ§in optimizasyon
        # Bu Ã¶rnekte genel optimizasyon kullanÄ±yoruz
        # GerÃ§ek uygulamada veri home/away'e gÃ¶re filtrelenmeli
        
        print("\n   ğŸ  Ev sahibi aÄŸÄ±rlÄ±klarÄ±...")
        home_results = self.optimize_general_weights()
        match_type_weights['home_advantage'] = home_results['weights']
        
        print("\n   âœˆï¸ Deplasman aÄŸÄ±rlÄ±klarÄ±...")
        away_results = self.optimize_general_weights()
        match_type_weights['away_advantage'] = away_results['weights']
        
        print("\n   âš–ï¸ NÃ¶tr saha aÄŸÄ±rlÄ±klarÄ±...")
        neutral_results = self.optimize_general_weights()
        match_type_weights['neutral'] = neutral_results['weights']
        
        match_type_results = {
            'match_type_weights': match_type_weights,
            'timestamp': datetime.now().isoformat()
        }
        
        return match_type_results
    
    def compare_with_baseline(self, optimized_weights: Dict) -> Dict:
        """Optimize edilmiÅŸ aÄŸÄ±rlÄ±klarÄ± baseline ile karÅŸÄ±laÅŸtÄ±r."""
        print("\nğŸ“Š Baseline karÅŸÄ±laÅŸtÄ±rmasÄ±...")
        
        # Baseline: EÅŸit aÄŸÄ±rlÄ±klar
        n_models = len(self.models)
        equal_weights = {name: 1.0/n_models for name in self.models.keys()}
        
        # Equal weights performansÄ±
        y_pred_equal = self.create_weighted_predictions(self.X_test, equal_weights)
        y_pred_equal_class = np.argmax(y_pred_equal, axis=1)
        
        equal_accuracy = accuracy_score(self.y_test, y_pred_equal_class)
        equal_f1 = f1_score(self.y_test, y_pred_equal_class, average='macro')
        
        # Optimized weights performansÄ±
        y_pred_opt = self.create_weighted_predictions(self.X_test, optimized_weights)
        y_pred_opt_class = np.argmax(y_pred_opt, axis=1)
        
        opt_accuracy = accuracy_score(self.y_test, y_pred_opt_class)
        opt_f1 = f1_score(self.y_test, y_pred_opt_class, average='macro')
        
        # Ä°yileÅŸme hesapla
        accuracy_improvement = ((opt_accuracy - equal_accuracy) / equal_accuracy) * 100
        f1_improvement = ((opt_f1 - equal_f1) / equal_f1) * 100
        
        comparison = {
            'baseline': {
                'weights': equal_weights,
                'accuracy': float(equal_accuracy),
                'f1_macro': float(equal_f1)
            },
            'optimized': {
                'weights': optimized_weights,
                'accuracy': float(opt_accuracy),
                'f1_macro': float(opt_f1)
            },
            'improvement': {
                'accuracy_percent': float(accuracy_improvement),
                'f1_percent': float(f1_improvement)
            }
        }
        
        print(f"\n   Baseline (Equal Weights):")
        print(f"      Accuracy: {equal_accuracy:.4f}")
        print(f"      F1-Score: {equal_f1:.4f}")
        
        print(f"\n   Optimized Weights:")
        print(f"      Accuracy: {opt_accuracy:.4f}")
        print(f"      F1-Score: {opt_f1:.4f}")
        
        print(f"\n   ğŸ‰ Ä°yileÅŸme:")
        print(f"      Accuracy: {accuracy_improvement:+.2f}%")
        print(f"      F1-Score: {f1_improvement:+.2f}%")
        
        return comparison
    
    def save_weights(self, weights: Dict, filename: str):
        """AÄŸÄ±rlÄ±klarÄ± kaydet."""
        filepath = self.output_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(weights, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ AÄŸÄ±rlÄ±klar kaydedildi: {filepath}")
    
    def run(self, mode: str = 'general'):
        """Optimizasyonu Ã§alÄ±ÅŸtÄ±r."""
        print("\n" + "="*80)
        print("ğŸ¯ ENSEMBLE AÄIRLIK OPTÄ°MÄ°ZASYONU")
        print("="*80)
        
        # Veri ve modelleri yÃ¼kle
        if not self.load_data():
            return
        
        if not self.load_models():
            print("âŒ Yeterli model bulunamadÄ±!")
            return
        
        results = {}
        
        # Mod seÃ§imine gÃ¶re optimizasyon
        if mode == 'general' or mode == 'all':
            print("\n" + "="*60)
            print("ğŸ“ MODE: GENEL OPTÄ°MÄ°ZASYON")
            print("="*60)
            
            general_results = self.optimize_general_weights()
            
            # Baseline ile karÅŸÄ±laÅŸtÄ±r
            comparison = self.compare_with_baseline(general_results['weights'])
            general_results['baseline_comparison'] = comparison
            
            # Kaydet
            self.save_weights(general_results, 'general_weights.json')
            results['general'] = general_results
        
        if mode == 'league' or mode == 'all':
            print("\n" + "="*60)
            print("ğŸ“ MODE: LÄ°G BAZLI OPTÄ°MÄ°ZASYON")
            print("="*60)
            
            league_results = self.optimize_league_weights()
            self.save_weights(league_results, 'league_weights.json')
            results['league'] = league_results
        
        if mode == 'match_type' or mode == 'all':
            print("\n" + "="*60)
            print("ğŸ“ MODE: MAÃ‡ TÄ°PÄ° BAZLI OPTÄ°MÄ°ZASYON")
            print("="*60)
            
            match_type_results = self.optimize_match_type_weights()
            self.save_weights(match_type_results, 'match_type_weights.json')
            results['match_type'] = match_type_results
        
        # Genel rapor
        final_report = {
            'optimization_mode': mode,
            'n_models': len(self.models),
            'model_names': list(self.models.keys()),
            'results': results,
            'timestamp': datetime.now().isoformat()
        }
        
        # Raporu kaydet
        report_path = self.output_dir / 'optimization_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)
        
        print("\n" + "="*80)
        print("âœ… OPTÄ°MÄ°ZASYON TAMAMLANDI!")
        print("="*80)
        print(f"\nğŸ“ Ã‡Ä±ktÄ±lar: {self.output_dir}")
        print(f"   â€¢ general_weights.json")
        print(f"   â€¢ optimization_report.json")
        if mode in ['league', 'all']:
            print(f"   â€¢ league_weights.json")
        if mode in ['match_type', 'all']:
            print(f"   â€¢ match_type_weights.json")
        
        return results


def main():
    """Ana fonksiyon."""
    parser = argparse.ArgumentParser(
        description='Ensemble model aÄŸÄ±rlÄ±klarÄ±nÄ± optimize et'
    )
    parser.add_argument(
        '--mode',
        type=str,
        default='general',
        choices=['general', 'league', 'match_type', 'all'],
        help='Optimizasyon modu (default: general)'
    )
    parser.add_argument(
        '--models-dir',
        type=str,
        default='models',
        help='Model dizini (default: models)'
    )
    parser.add_argument(
        '--data-dir',
        type=str,
        default='prepared_data',
        help='Veri dizini (default: prepared_data)'
    )
    parser.add_argument(
        '--n-calls',
        type=int,
        default=50,
        help='Bayesian optimization iterations (default: 50)'
    )
    
    args = parser.parse_args()
    
    # Optimizer oluÅŸtur
    optimizer = EnsembleWeightOptimizer(
        models_dir=args.models_dir,
        data_dir=args.data_dir
    )
    optimizer.n_calls = args.n_calls
    
    # Ã‡alÄ±ÅŸtÄ±r
    optimizer.run(mode=args.mode)


if __name__ == "__main__":
    main()
